{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Analysis Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "Use these links to jump to specific sections of this assignment!\n",
    "\n",
    "- [1. Introduction](#1)\n",
    "- [2. Installation](#2)\n",
    "    - [2.1 Install mmclassification in CS GPU Farm](#2.1)\n",
    "    - [2.2 2.2 Verify mmclassification and Pytorch in CS GPU Farm](#2.2)\n",
    "- [3. Download and check the Dataset](#3)\n",
    "    - [3.1 Download](#3.1)\n",
    "    - [3.1 Refomating](#3.2)\n",
    "- [4. Train a new classifier on customized dataset](#4)\n",
    "- [5. Test](#5)\n",
    "- [5. Improvement](#6)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI8PBrk_2Z4V"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1. IntroductionÂ¶\n",
    "Among a variety of medical imaging modalities, chest X-ray is one of the most common and readily available examinations for diagnosing chest diseases. It is primarily used to screen diseases such as lung cancer, pneumonia, tuberculosis and pneumothorax to detect them at their earliest and most treatable stage. However, the problem lies in the heavy workload of reading chest X-rays. Radiologists usually read tens or hundreds of X-rays every day. Several studies regarding radiologic errors have reported that 20-30% of exams are misdiagnosed. To compensate for this shortcoming, many hospitals equip radiologists with **computer-aided diagnosis systems**. In this toturial, we will build and train **a multi-label classifier** to detect possible chest diseases among the chest X-ray images. The overall workfolw is shown as below:\n",
    "\n",
    "\n",
    "![Cat](figures/tutorial_overall.jpg)\n",
    "\n",
    "Through the tutorial, you will learn:\n",
    "- How to train a chest diseases multi-label classifier?\n",
    "- How to infer the trained model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2. Installation\n",
    "We use the MMClassification package to construct our training and testing pipeline. MMClassification is an open source image classification toolbox based on PyTorch.\n",
    "<a name='2.1'></a>\n",
    "### 2.1 Install mmclassification in CS GPU Farm\n",
    "\n",
    "1. Create a conda virtual environment and activate it. We call the new environment as open-mmlab.\n",
    "    ```shell\n",
    "    conda create -n open-mmlab python=3.7 -y\n",
    "    conda activate open-mmlab\n",
    "    ```  \n",
    "2. Install Pytorch and Torchvison following the [offcial guidance](https://pytorch.org/get-started/locally/).\n",
    "    ```shell\n",
    "    conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=10.1 -c pytorch\n",
    "    ``` \n",
    "3. Install mmcv from source code.\n",
    "    ```shell\n",
    "    git clone https://github.com/open-mmlab/mmcv.git\n",
    "    cd mmcv\n",
    "    MMCV_WITH_OPS=1 pip install -e .  # package mmcv-full will be installed after this step\n",
    "    cd ..\n",
    "    ``` \n",
    "4. Install mmclassification form source code\n",
    "    ```shell\n",
    "    git clone https://github.com/open-mmlab/mmclassification.git\n",
    "    cd mmclassification\n",
    "    python setup.py develop\n",
    "    ``` \n",
    "    \n",
    "<a name='2.2'></a>    \n",
    "### 2.2 Verify mmclassification and Pytorch in CS GPU Farm\n",
    "```python\n",
    "# check pytorch\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "# check mmclssification\n",
    "import mmcls\n",
    "print(mmcls.__version__)\n",
    "# check mmcv\n",
    "import mmcv\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(mmcv.__version__)\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PMDCWQRn5yA"
   },
   "source": [
    "<a name='3'></a>\n",
    "## 3. Download and check the Dataset\n",
    "\n",
    "For this assignment, we will be using the [ChestX-ray8 dataset](https://arxiv.org/abs/1705.02315) which contains 108,948 frontal-view X-ray images of 32,717 unique patients. In summary:\n",
    "- Each image in the data set contains multiple text-mined labels identifying 14 different pathological conditions. \n",
    "- We will use this data to develop a single model that will provide binary classification predictions for each of the 14 labeled pathologies. \n",
    "- In other words it will predict 'positive' or 'negative' for each of the pathologies.\n",
    " \n",
    "This dataset has been annotated by consensus among four different radiologists for our 14 pathologies:\n",
    "- `Cardiomegaly`, \n",
    "- `Emphysema`, \n",
    "- `Effusion`, \n",
    "- `Hernia`, \n",
    "- `Infiltration`, \n",
    "- `Mass`, \n",
    "- `Nodule`, \n",
    "- `Atelectasis`,\n",
    "- `Pneumothorax`,\n",
    "- `Pleural_Thickening`, \n",
    "- `Pneumonia`, \n",
    "- `Fibrosis`, \n",
    "- `Edema`, \n",
    "- `Consolidation`\n",
    "\n",
    "<a name='3.1'></a>\n",
    "### 3.1 Download\n",
    "We downlaod the whole dataset via the kaggle websites:\n",
    "- Register your [Kaggle] (https://www.kaggle.com/) account \n",
    "- Download the ChesyX-ray8 dataset from https://www.kaggle.com/nih-chest-xrays/data, and FTP the downloaded dataset to your GPU farm via FTP tool.\n",
    "- Or you can download the dataset to GPU farm directly.\n",
    "   - Typing cmd \"pip install kaggle\" in GPU farm to install [kaggle api](https://github.com/Kaggle/kaggle-api) so that you can download the dataset via the command line.\n",
    "   - Typing cmd \"kaggle datasets download -d nih-chest-xrays/data\" to download dataset.\n",
    "  \n",
    "<a name='3.2'></a>\n",
    "### 3.2 Refomating\n",
    "- We rename the dataset to \"cxr14\" and move to the *data* folder under mmclssification.\n",
    "    ```shell\n",
    "    mv nih-chest-xrays cxr14\n",
    "    mkdir data\n",
    "    mv cxr14 data\n",
    "    ``` \n",
    "- The directory should be like that\n",
    "```\n",
    "cxr14\n",
    "     |--images\n",
    "          |--00012163_001.png\n",
    "          |--00012163_001.png\n",
    "          ...   \n",
    "     |--labels\n",
    "          |--train.csv\n",
    "          |--val.csv\n",
    "          |--test.csv   \n",
    "``` \n",
    "- We convert the csv annotation to txt format\n",
    "\n",
    "```python\n",
    "import pandas\n",
    "import numpy as np\n",
    "CLASSES = [\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\", \"Mass\", \"Nodule\", \"Pneumonia\",\n",
    "           \"Pneumothorax\", \"Consolidation\", \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"]\n",
    "\n",
    "for item in [\"train\", \"val\", \"test\"]:\n",
    "    object_csv = f\"/apdcephfs/share_1364275/yuanfengji/data/medical/xray/cxr14/labels/{item}.csv\"\n",
    "    target_txt = f\"/apdcephfs/share_1364275/yuanfengji/data/medical/xray/cxr14/labels/{item}.txt\"\n",
    "\n",
    "    object = pandas.read_csv(object_csv)\n",
    "\n",
    "    image_idx = list(object[\"Image Index\"])\n",
    "    label_idx = list(object[\"Finding Labels\"])\n",
    "    write_strings = []\n",
    "\n",
    "    for image_id, label_id in zip(image_idx, label_idx):\n",
    "        num_labels = np.zeros((14))\n",
    "        lables = label_id.split(\"|\")\n",
    "        for item in lables:\n",
    "            if item == \"No Finding\":\n",
    "                pass\n",
    "            else:\n",
    "                idx = CLASSES.index(item)\n",
    "                num_labels[idx] = 1\n",
    "\n",
    "        write_strings.append(image_id+\" \"+' '.join(str(int(x)) for x in num_labels))\n",
    "\n",
    "    with open(target_txt, 'w') as f:\n",
    "        for item in write_strings:\n",
    "            f.write(item+'\\n')\n",
    "    f.close()\n",
    "``` \n",
    "\n",
    "- Check the convert annotation\n",
    "```\n",
    "!cat data/cxr/labels/train.txt\n",
    "``` \n",
    "The output shold be:\n",
    "```\n",
    "00000001_000.png 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "00000001_001.png 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
    "00000001_002.png 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
    "00000002_000.png 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "00000004_000.png 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
    "00000005_000.png 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "00000005_001.png 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "00000005_002.png 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "00000005_003.png 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "00000005_004.png 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "00000005_005.png 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4. Train a new classifier on customized dataset\n",
    "\n",
    "### 4.1 Support  CXR14 dataset to mmcls package.\n",
    "\n",
    "In ```mmclassification/mmcls/datasets```, We follow the file ```imagenet.py``` to write a dataset class file \"cxr14.py\". Simply, we can copy 'imagenet.py' and re-write it's classes here:\n",
    "\n",
    "```python\n",
    "@DATASETS.register_module()\n",
    "class CXR14(BaseDataset):\n",
    "\n",
    "    IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif')\n",
    "    CLASSES = [\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\", \"Mass\", \"Nodule\", \"Pneumonia\",\n",
    "               \"Pneumothorax\", \"Consolidation\", \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"]\n",
    "\n",
    "    def load_annotations(self):\n",
    "        if self.ann_file is None:\n",
    "            folder_to_idx = find_folders(self.data_prefix)\n",
    "            samples = get_samples(\n",
    "                self.data_prefix,\n",
    "                folder_to_idx,\n",
    "                extensions=self.IMG_EXTENSIONS)\n",
    "            if len(samples) == 0:\n",
    "                raise (RuntimeError('Found 0 files in subfolders of: '\n",
    "                                    f'{self.data_prefix}. '\n",
    "                                    'Supported extensions are: '\n",
    "                                    f'{\",\".join(self.IMG_EXTENSIONS)}'))\n",
    "\n",
    "            self.folder_to_idx = folder_to_idx\n",
    "        elif isinstance(self.ann_file, str):\n",
    "            samples = []\n",
    "            with open(self.ann_file) as f:\n",
    "                for line in f.readlines():\n",
    "                    items = line.strip().split(' ')\n",
    "                    filename = items[0]\n",
    "                    label = [int(i) for i in items[1:]]\n",
    "                    samples.append([filename, label])\n",
    "        else:\n",
    "            raise TypeError('ann_file must be a str or None')\n",
    "        self.samples = samples\n",
    "\n",
    "        data_infos = []\n",
    "        for filename, gt_label in self.samples:\n",
    "            info = {'img_prefix': self.data_prefix}\n",
    "            info['img_info'] = {'filename': filename}\n",
    "            info['gt_label'] = np.array(gt_label, dtype=np.float)\n",
    "            data_infos.append(info)\n",
    "        return data_infos\n",
    "```\n",
    "It should be note that we need to import 'CXR14' class in the ```_init_.py``` under ```mmclassification/mmcls/datasets```, so that the mmcls can locate and register the CXR14 scucessfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Set the logs file for Model Training\n",
    "Now we'll move on to model training, Suppose we are at 'mmclassification/configs/__base__' directory.\n",
    "#### 4.2.1 Set the datset config\n",
    "In ```_base_/datasets```, we add ```cxr14_bs32.py``` to describle the basic config about data. Note that we need to declare the necessary data paths and data pipelines in it like this:\n",
    "```python\n",
    "dataset_type = 'CXR14'\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='RandomResizedCrop', size=224),\n",
    "    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='ImageToTensor', keys=['img']),\n",
    "    dict(type='ToTensor', keys=['gt_label']),\n",
    "    dict(type='Collect', keys=['img', 'gt_label'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', size=(256, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='ImageToTensor', keys=['img']),\n",
    "    dict(type='Collect', keys=['img'])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=32,\n",
    "    workers_per_gpu=4,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        data_prefix='data/medical/cxr14/images',\n",
    "        ann_file='data/medical/cxr14/labels/trainval.txt',\n",
    "        pipeline=train_pipeline),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        data_prefix='data/medical/cxr14/images',\n",
    "        ann_file='data/medical/cxr14/labels/test.txt',\n",
    "        pipeline=test_pipeline),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        data_prefix='data/medical/cxr14/images',\n",
    "        ann_file='data/medical/cxr14/labels/val.txt',\n",
    "        pipeline=test_pipeline))\n",
    "evaluation = dict(\n",
    "    interval=1, metric=['mAP', 'AUC', 'CP', 'OP', 'CR', 'OR', 'CF1', 'OF1'], tta=False)\n",
    "```\n",
    "#### 4.2.2 Set the model config\n",
    "In ``_base_/models``, we added ``resnet50_cxr14.py`` to describe the basic configuration about the model. Note that we use the ``resnet-50`` model as backbone, and then add two layers on top of it:\n",
    "1. A `GlobalAveragePooling2D` layer to get the average of the last convolution layers from Resnet50.\n",
    "2. A `MultiLabelClsHead` layer with `sigmoid` activation to get the prediction logits for each of our classes.\n",
    "Here the ''num_classes'' is set to 14 because the total number of classes for chest diseases is 14.\n",
    "\n",
    "```python\n",
    "model = dict(\n",
    "    type='ImageClassifier',\n",
    "    backbone=dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(3,),\n",
    "        style='pytorch'),\n",
    "    neck=dict(type='GlobalAveragePooling'),\n",
    "    head=dict(\n",
    "        type='MultiLabelClsHead',\n",
    "        in_channels=2048,\n",
    "        num_classes=14,\n",
    "        loss=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))\n",
    " ```   \n",
    "#### 4.2.3 Set the training schedule config\n",
    "In ``_base_/schedules``, we added ``cxr14_bs32_ep20.py`` to develop the basic configuration about the training plan.Here we adopt \"AdamW\" optimizer and set lr to 3e-4 with a setp learning scheduler, which decay the lr decay in 10th and 15th. The total training epoch is set to 20. Meanwhile, we load weight pretrained on ImageNet datset.\n",
    "```python\n",
    "optimizer = dict(type='AdamW', lr=0.003, weight_decay=0.3) \n",
    "optimizer_config = dict(grad_clip=None)\n",
    "lr_config = dict(policy='step', step=[10, 15])\n",
    "runner = dict(type='EpochBasedRunner', max_epochs=20)\n",
    "```\n",
    "#### 4.2.4 Set the logging and saving config\n",
    "In ``_base_/schedules``, we set the ``default_runtime.py`` as follow:\n",
    "```python\n",
    "# checkpoint saving\n",
    "checkpoint_config = dict(interval=1)\n",
    "# yapf:disable\n",
    "log_config = dict(\n",
    "    interval=100,\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook'),\n",
    "        dict(type='TensorboardLoggerHook')\n",
    "    ])\n",
    "# yapf:enable\n",
    "\n",
    "dist_params = dict(backend='nccl')\n",
    "log_level = 'INFO'\n",
    "load_from = 'weights/resnet50_batch256_imagenet_20200708-cfb998bf.pth'\n",
    "resume_from = None\n",
    "workflow = [('train', 1)]\n",
    "```\n",
    "\n",
    "#### 4.2.5 Import configs for model training\n",
    "we create a config file in ``mmclassification/configs/resnet/resnet50_cxr14_bs32.py``. we import these config.py files into this file as\n",
    "```python\n",
    "_base_ = [\n",
    "    '../_base_/datasets/cxr14_bs32.py', '../_base_/models/resnet50_cxr14.py',\n",
    "    '../_base_/schedules/cxr14_bs32_ep20.py', '../_base_/default_runtime.py'\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Training\n",
    "In your 'mmclassification' directory, we run cmd:\n",
    "```shell\n",
    "python tools/train.py configs/resnet/resnet50_cxr14_bs32.py --work_dir 'work_dirs/resnet50_cxr14_bs32'\n",
    "```\n",
    "It should be note that we need to state the  training configuration 'configs/resnet/resnet50_cxr14_bs32.py' and the work_dir is used for saving the training results (model and log files). In such case, the trained model and logs are saved in work_dirs/resnet50_cxr14_bs32. Now, we change the directory to work_dirs/resnet50_cxr14_bs32 and we should get the saved model and log files.\n",
    "\n",
    "We show an example of training log, with a mean auc of 81.5%.\n",
    "```shell\n",
    "2021-10-04 16:43:02,050 - mmcls - INFO - Environment info:\n",
    "------------------------------------------------------------\n",
    "sys.platform: linux\n",
    "Python: 3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]\n",
    "CUDA available: True\n",
    "GPU 0: Tesla V100-SXM2-32GB\n",
    "CUDA_HOME: /usr/local/cuda\n",
    "NVCC: Build cuda_11.1.TC455_06.29190527_0\n",
    "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\n",
    "PyTorch: 1.8.0a0+1606899\n",
    "PyTorch compiling details: PyTorch built with:\n",
    "  - GCC 9.3\n",
    "  - C++ Version: 201402\n",
    "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
    "  - Intel(R) MKL-DNN v1.6.0 (Git Hash N/A)\n",
    "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
    "  - NNPACK is enabled\n",
    "  - CPU capability usage: AVX2\n",
    "  - CUDA Runtime 11.1\n",
    "  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_86,code=compute_86\n",
    "  - CuDNN 8.0.5\n",
    "  - Magma 2.5.2\n",
    "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, FORCE_FALLBACK_CUDA_MPI=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
    "\n",
    "TorchVision: 0.9.0a0\n",
    "OpenCV: 4.4.0\n",
    "MMCV: 1.3.4\n",
    "MMCV Compiler: n/a\n",
    "MMCV CUDA Compiler: n/a\n",
    "MMClassification: 0.11.0+\n",
    "------------------------------------------------------------\n",
    "\n",
    "2021-10-04 16:43:02,050 - mmcls - INFO - Distributed training: False\n",
    "2021-10-04 16:43:02,185 - mmcls - INFO - Config:\n",
    "model = dict(\n",
    "    type='ImageClassifier',\n",
    "    backbone=dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(3, ),\n",
    "        style='pytorch'),\n",
    "    neck=dict(type='GlobalAveragePooling'),\n",
    "    head=dict(\n",
    "        type='MultiLabelClsHead',\n",
    "        in_channels=2048,\n",
    "        num_classes=14,\n",
    "        loss=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)))\n",
    "dataset_type = 'CXR14'\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='RandomResizedCrop', size=224),\n",
    "    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        to_rgb=True),\n",
    "    dict(type='ImageToTensor', keys=['img']),\n",
    "    dict(type='ToTensor', keys=['gt_label']),\n",
    "    dict(type='Collect', keys=['img', 'gt_label'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', size=(256, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        to_rgb=True),\n",
    "    dict(type='ImageToTensor', keys=['img']),\n",
    "    dict(type='Collect', keys=['img'])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=32,\n",
    "    workers_per_gpu=4,\n",
    "    train=dict(\n",
    "        type='CXR14',\n",
    "        data_prefix='data/medical/cxr14/images',\n",
    "        ann_file='data/medical/cxr14/labels/trainval.txt',\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='RandomResizedCrop', size=224),\n",
    "            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
    "            dict(\n",
    "                type='Normalize',\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='ToTensor', keys=['gt_label']),\n",
    "            dict(type='Collect', keys=['img', 'gt_label'])\n",
    "        ]),\n",
    "    val=dict(\n",
    "        type='CXR14',\n",
    "        data_prefix='data/medical/cxr14/images',\n",
    "        ann_file='data/medical/cxr14/labels/test.txt',\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='Resize', size=(256, 256)),\n",
    "            dict(type='CenterCrop', crop_size=224),\n",
    "            dict(\n",
    "                type='Normalize',\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ]),\n",
    "    test=dict(\n",
    "        type='CXR14',\n",
    "        data_prefix='data/medical/cxr14/images',\n",
    "        ann_file='data/medical/cxr14/labels/val.txt',\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='Resize', size=(256, 256)),\n",
    "            dict(type='CenterCrop', crop_size=224),\n",
    "            dict(\n",
    "                type='Normalize',\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ]))\n",
    "evaluation = dict(\n",
    "    interval=1,\n",
    "    metric=['mAP', 'AUC', 'CP', 'OP', 'CR', 'OR', 'CF1', 'OF1'],\n",
    "    tta=False)\n",
    "optimizer = dict(\n",
    "    type='Adam', lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-05)\n",
    "optimizer_config = dict(grad_clip=None)\n",
    "lr_config = dict(policy='step', step=[15, 18])\n",
    "runner = dict(type='EpochBasedRunner', max_epochs=20)\n",
    "checkpoint_config = dict(interval=1)\n",
    "log_config = dict(\n",
    "    interval=100,\n",
    "    hooks=[dict(type='TextLoggerHook'),\n",
    "           dict(type='TensorboardLoggerHook')])\n",
    "dist_params = dict(backend='nccl')\n",
    "log_level = 'INFO'\n",
    "load_from = 'weights/resnet50_batch256_imagenet_20200708-cfb998bf.pth'\n",
    "resume_from = None\n",
    "workflow = [('train', 1)]\n",
    "work_dir = './work_dirs/res50_b128_cxr14_ep20'\n",
    "gpu_ids = range(0, 1)\n",
    "\n",
    "2021-10-04 16:43:06,193 - mmcls - INFO - load checkpoint from weights/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
    "2021-10-04 16:43:06,194 - mmcls - INFO - Use load_from_local loader\n",
    "2021-10-04 16:43:06,479 - mmcls - WARNING - The model and loaded state dict do not match exactly\n",
    "\n",
    "size mismatch for head.fc.weight: copying a param with shape torch.Size([1000, 2048]) from checkpoint, the shape in current model is torch.Size([14, 2048]).\n",
    "size mismatch for head.fc.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([14]).\n",
    "2021-10-04 16:43:06,484 - mmcls - INFO - Start running, host: root@ts-e961c55f4d024bdabd98f3f81128cc20-launcher, work_dir: /apdcephfs/share_1364275/yuanfengji/project/mmclassification/work_dirs/res50_b128_cxr14_ep20\n",
    "2021-10-04 16:43:06,485 - mmcls - INFO - workflow: [('train', 1)], max: 20 epochs\n",
    "2021-10-04 16:44:23,656 - mmcls - INFO - Epoch [1][100/676]\tlr: 1.000e-04, eta: 2:52:11, time: 0.770, data_time: 0.376, memory: 10963, loss: 2.8662\n",
    "2021-10-04 16:45:40,562 - mmcls - INFO - Epoch [1][200/676]\tlr: 1.000e-04, eta: 2:50:49, time: 0.769, data_time: 0.395, memory: 10963, loss: 2.0961\n",
    "2021-10-04 16:46:52,274 - mmcls - INFO - Epoch [1][300/676]\tlr: 1.000e-04, eta: 2:45:41, time: 0.717, data_time: 0.343, memory: 10963, loss: 2.0498\n",
    "2021-10-04 16:48:07,000 - mmcls - INFO - Epoch [1][400/676]\tlr: 1.000e-04, eta: 2:44:10, time: 0.747, data_time: 0.373, memory: 10963, loss: 2.0500\n",
    "2021-10-04 16:49:26,798 - mmcls - INFO - Epoch [1][500/676]\tlr: 1.000e-04, eta: 2:44:58, time: 0.798, data_time: 0.424, memory: 10963, loss: 1.9722\n",
    "2021-10-04 16:50:56,585 - mmcls - INFO - Epoch [1][600/676]\tlr: 1.000e-04, eta: 2:48:38, time: 0.898, data_time: 0.523, memory: 10963, loss: 2.0262\n",
    "2021-10-04 16:54:45,665 - mmcls - INFO - Saving checkpoint at 1 epochs\n",
    "2021-10-04 16:54:46,312 - mmcls - INFO - Epoch(val) [1][676]\tAP-Atelectasis: 30.2678, AP-Cardiomegaly: 24.7547, AP-Effusion: 47.3578, AP-Infiltration: 37.4045, AP-Mass: 23.1604, AP-Nodule: 19.5599, AP-Pneumonia: 4.2387, AP-Pneumothorax: 36.9074, AP-Consolidation: 13.7337, AP-Edema: 12.6109, AP-Emphysema: 30.0434, AP-Fibrosis: 6.2853, AP-Pleural_Thickening: 10.3355, AP-Hernia: 1.5504, AP: 21.3007, AUC-Atelectasis: 74.3349, AUC-Cardiomegaly: 81.2567, AUC-Effusion: 80.7166, AUC-Infiltration: 67.6402, AUC-Mass: 74.6935, AUC-Nodule: 72.7235, AUC-Pneumonia: 67.9964, AUC-Pneumothorax: 83.0441, AUC-Consolidation: 71.9170, AUC-Edema: 81.8726, AUC-Emphysema: 84.3682, AUC-Fibrosis: 76.6358, AUC-Pleural_Thickening: 71.1178, AUC-Hernia: 76.1133, AUC: 76.0308, CP: 28.3498, CR: 3.2353, CF1: 5.8079, OP: 53.0561, OR: 6.9874, OF1: 12.3486\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5. Test\n",
    "We select ``data/cxr14/images/00030805_000.png`` as test image, which as shown blow:\n",
    "![Cat](figures/00030805_000.png)\n",
    "\n",
    "We can  get prediciton results from trained  model by running:\n",
    "```python\n",
    "python demo/image_demo.py \\\n",
    "  --img 'data/cxr14/images/00030805_000.png'\\ \n",
    "  --config 'configs/resnet/resnet50_cxr14_bs32.py' \\\n",
    "  --checkpoint 'output/resnet50_cxr14_bs32/epoch_13.pth'\n",
    "```\n",
    "The expected output should be close to:\n",
    "{'pred_label': [0, 1], 'pred_score': [0.9812, 0.8745], 'pred_class': 'Cardiomegaly', 'Emphysema'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA90g8n6suRV"
   },
   "source": [
    "<a name='6'></a>\n",
    "## 6. Improvement\n",
    "- Now we can access a new covid 19 xray dataset, how can we use it to extend model to detect covid 19 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
